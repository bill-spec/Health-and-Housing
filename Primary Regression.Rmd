---
title: "Primary Regression"
author: "Bill Lang"
date: "1/25/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(glmnet)
library(car)       #vif
library(rpart)     #Tree
library(partykit) #Special Tree Stuff
library(MASS)
library(caret)
library(leaps)
library(ggthemes)
library(alr3)
library(moments)
```

Reading in the data.

```{r}
head(dataSet)
head(dataSetSmall)
```

```{r}
cor(dataSetSmall)
```



```{r}
ggplot(gather(data = dataSetSmall), aes(value)) + 
    geom_histogram(bins = 10) + 
    facet_wrap(~key, scales = 'free_x')+
  theme_fivethirtyeight()
```

```{r}
pairs(rentTotalPop ~ TotalPercentEBLL15_18 + anxietyPorportion + depressionPorportion + hyper2Porportion + Dia2Porportion  + percent.of.vacant.properties, dataSet)
```

Single Variable Models

```{r}
anxietyModel <- lm(rentTotalPop~anxietyPorportion,dataSetSmall)
depressionModel <- lm(rentTotalPop~depressionPorportion,dataSetSmall)
hypertensionModel <- lm(rentTotalPop~hyper2Porportion,dataSetSmall)
diabetesModel <- lm(rentTotalPop~Dia2Porportion,dataSetSmall)

summary(anxietyModel)$coef[2,1]
summary(depressionModel)$coef[2,1]
summary(hypertensionModel)$coef[2,1]
summary(diabetesModel)$coef[2,1]
```

Multi-Variate Models.
Collinearity looks okay. 

```{r}
renterModel <- lm(rentTotalPop ~  anxietyPorportion +depressionPorportion + hyper2Porportion + Dia2Porportion + TotalPopulation, data = dataSetSmall)
summary(renterModel)

anova(renterModel)

vif(renterModel)
```


**Adding in the interaction terms**

Test for Coincidence

This is effectively our maximum model.

```{r}
renterModelInteraction <- lm(rentTotalPop~ TotalPercentEBLL15_18 + anxietyPorportion + depressionPorportion + hyper2Porportion + Dia2Porportion + TotalPopulation + TotalPercentEBLL15_18:anxietyPorportion + TotalPercentEBLL15_18:depressionPorportion + TotalPercentEBLL15_18:hyper2Porportion + TotalPercentEBLL15_18:Dia2Porportion, data = dataSetSmall)

anova(renterModel,renterModelInteraction)
```

Test for the parallelism

```{r}
renterModelInteractionFull <- lm(rentTotalPop~ TotalPercentEBLL15_18 + anxietyPorportion + depressionPorportion + hyper2Porportion +  Dia2Porportion + TotalPopulation + TotalPercentEBLL15_18:anxietyPorportion + TotalPercentEBLL15_18:depressionPorportion + TotalPercentEBLL15_18:hyper2Porportion + TotalPercentEBLL15_18:Dia2Porportion, data = dataSet)

RenterModelInteraction1 <- lm(rentTotalPop~ TotalPercentEBLL15_18 + anxietyPorportion + depressionPorportion + hyper2Porportion + Dia2Porportion + TotalPopulation + TotalPercentEBLL15_18:depressionPorportion + TotalPercentEBLL15_18:hyper2Porportion + TotalPercentEBLL15_18:Dia2Porportion, data = dataSet)

RenterModelInteraction2 <- lm(rentTotalPop~ TotalPercentEBLL15_18 + anxietyPorportion + depressionPorportion + hyper2Porportion + Dia2Porportion + TotalPopulation+ TotalPercentEBLL15_18:anxietyPorportion + TotalPercentEBLL15_18:hyper2Porportion + TotalPercentEBLL15_18:Dia2Porportion, data = dataSet)

RenterModelInteraction3 <- lm(rentTotalPop~ TotalPercentEBLL15_18 + anxietyPorportion + depressionPorportion + hyper2Porportion + Dia2Porportion + TotalPopulation +TotalPercentEBLL15_18:anxietyPorportion + TotalPercentEBLL15_18:depressionPorportion + TotalPercentEBLL15_18:Dia2Porportion, data = dataSet)

RenterModelInteraction4 <- lm(rentTotalPop~ TotalPercentEBLL15_18 + anxietyPorportion + depressionPorportion + hyper2Porportion + Dia2Porportion + TotalPopulation +TotalPercentEBLL15_18:anxietyPorportion + TotalPercentEBLL15_18:depressionPorportion + TotalPercentEBLL15_18:hyper2Porportion, data = dataSet)

```

```{r}
anova(RenterModelInteraction1,renterModelInteractionFull)
anova(RenterModelInteraction2, renterModelInteractionFull)
anova(RenterModelInteraction3,renterModelInteractionFull)
anova(RenterModelInteraction4, renterModelInteractionFull)
```

Trimmed Model; Full Model

```{r}
fullModel <- lm(rentTotalPop~ TotalPercentEBLL15_18 + anxietyPorportion + depressionPorportion + hyper2Porportion + Dia2Porportion + TotalPopulation +  TotalPercentEBLL15_18:anxietyPorportion + TotalPercentEBLL15_18:depressionPorportion, data = dataSetSmall)

summary(fullModel)
vif(fullModel)
```

```{r}
dataSetSmall <- dataSet %>% mutate(rentSqaure = rentTotalPop^2)
```

```{r}
?histogram
histogram(rstudent(fullModel), breaks = 50,
     xlab = "Frequency", ylab = "Studentized Residuals",               # Labels
     axes = FALSE,                                                      # Don't plot the axes
     frame.plot = FALSE,                                                 # Remove the frame 
     xlim = c(-4,6), ylim = c(0, 10), col = "grey80")      

# Limits
     panel.first = abline(h = c(-2, 0,2,4,6), col = "grey80"))


skewness(rstudent(fullModel))
kurtosis(rstudent(fullModel))
```


```{r}
par(mfrow = c(2,2))
plot(fullModel)
```


**Diagnostics**

Testing Independence

```{r}
a <- rstudent(renterModelInteractionTrimmed)
b <- c(1:387)
df <- data.frame("Studentized Residuals" = a, "Observation.Number"<- b)
```

```{r}
par(mar = c(3, 3, 2, 1), # Dist' from plot to side of page
    mgp = c(2, 0.4, 0), # Dist' plot to label
    las = 1, # Rotate y-axis text
    tck = -.01) # Reduce tick length
plot(jitter(df$X.Observation.Number.....b),jitter(df$Studentized.Residuals), type = 'b',
     pch = 20, # Shape: circles that can filed
     xlab = "Observation Number", ylab = "Studentized Residuals", # Labels
     axes = FALSE, # Don't plot the axes
     frame.plot = FALSE, # Remove the frame 
     xlim = c(0, 400), ylim = c(-3, 6), # Limits
     panel.first = abline(h = c(-2, 0,2,4,6), col = "grey80"))
abline(h = 0, col ='red')
at = pretty(df$X.Observation.Number.....b)
mtext(side = 1, text = at, at = at, col = "grey20", line = 1, cex = 0.9)
at = pretty(df$Studentized.Residuals)
mtext(side = 2, text = at, at = at, col = "grey20", line = 1, cex = 0.9)
#title("Table (Number)", adj = 1, 
      #cex.main = 0.8, font.main = 2, col.main = "black")
```

Homoskedasticity 

```{r}
a <- rstudent(renterModelInteractionTrimmed)
b <- renterModelInteractionTrimmed$fitted.values
df <- data.frame("Studentized Residuals" = a, "Fitted Values"<- b)
```

```{r}
par(mar = c(3, 3, 2, 1), # Dist' from plot to side of page
    mgp = c(2, 0.4, 0), # Dist' plot to label
    las = 1, # Rotate y-axis text
    tck = -.01) # Reduce tick length
plot(jitter(df$X.Fitted.Values.....b),jitter(df$Studentized.Residuals),
     pch = 20, # Shape: circles that can filed
     xlab = "Fitted Values", ylab = "Studentized Residuals", # Labels
     axes = FALSE, # Don't plot the axes
     frame.plot = FALSE, # Remove the frame 
     xlim = c(0, 0.8), ylim = c(-4, 6), # Limits
     panel.first = abline(h = c(-4,-2, 0,2,4,6), col = "grey80"))
abline(h = 0, col ='red')
at = pretty(df$X.Fitted.Values.....b)
mtext(side = 1, text = at, at = at, col = "grey20", line = 1, cex = 0.9)
at = pretty(df$Studentized.Residuals)
mtext(side = 2, text = at, at = at, col = "grey20", line = 1, cex = 0.9)
#title("Table (Number)", adj = 1, 
#      cex.main = 0.8, font.main = 2, col.main = "black")
```

Unqiue Observations

```{r}
doubleAverage <- ((2*(7+1))/dim(dataSetSmall)[1])
criticalValue <- qt(c(.025, .975), df=378) 

cooksDistance <- cooks.distance(renterModelInteractionTrimmed)
leverage <- hatvalues(renterModelInteractionTrimmed)
stud <- rstudent(renterModelInteractionTrimmed)
obs <- c(1:387)

dfObs <- data.frame(obs,leverage, cooksDistance, stud)
```

```{r}
highLeverage <- dfObs %>% filter(leverage > doubleAverage)
outlier <- dfObs %>% filter(stud > criticalValue[2] | stud < criticalValue[1])
influential <- dfObs %>% filter(cooksDistance > 1)
dim(outlier);dim(highLeverage)
```

We find no influential points but there is a signifigant amount of outliers. 

```{r}
leverage <- highLeverage
outliers <- outlier

hist(highLeverage$leverage, 50)
hist(outliers$stud,22)

oddObservations <- leverage %>% full_join(outliers, by = c("obs", "leverage", "cooksDistance", "stud")) 
oddObservations
```

**Investigating the outliers**
Taking the averages and standard deviations of our outliers observations to see if they are dramtically out of line with the origional hisotgrams. 

```{r}
superSetOutliers <- dataSet[outliers$obs,]
superSetLeverage <- dataSet[leverage$obs,]

lev <- superSetLeverage %>% summarise_all(mean)
out <- superSetOutliers %>% summarise_all(mean)
```


```{r}
subSet <- dataSetSmall[-oddObservations$obs,] 
hm <- subSet %>% summarise_all(mean)
var <- summarise_all(subSet, sd)

names <- c("leverage","Outliers","Rest of Data","Standard Deviation across all Data")
df_compare <- rbind(hm,dfOdd,sd)
df_compare <- df_compare %>% column_to_rownames(names)
```

**Model Produced with only non-outlier data**

Super clean, probably contains super high varience. 

```{r}
modelSubSet <- lm(rentTotalPop~ TotalPercentEBLL15_18 + anxietyPorportion + depressionPorportion + hyper2Porportion + Dia2Porportion + TotalPercentEBLL15_18:anxietyPorportion + TotalPercentEBLL15_18:depressionPorportion, data = subSet)

summary(modelSubSet)
vif(modelSubSet)
```

```{r}
dataSet <- dataSet %>% mutate(rentSqaure = rentTotalPop^2)
```

```{r}
par(mfrow = c(2,2))
plot(modelSubSet)
```

```{r}
plot(modelSubSet$fitted.values,rstudent(modelSubSet))
```


Best Subset Selection. 

Looking at the plots we can see that we should probably remove those variables that attempt to find interaction between diabetes and hypertension. The average lead amoung for the region has also been removed in all the variable selective models. It will be left in for the time being for heiracrchical organziation as it would remain as an interaction term between anxiety and depression anyways. 

**Can be imporved by only using the training datasets to select as this will be have high varience**

```{r}
regfull <- regsubsets(rentTotalPop~ TotalPercentEBLL15_18 + anxietyPorportion + depressionPorportion + hyper2Porportion + Dia2Porportion + TotalPopulation + percent.of.vacant.properties + TotalPercentEBLL15_18:anxietyPorportion + TotalPercentEBLL15_18:depressionPorportion + TotalPercentEBLL15_18:hyper2Porportion + TotalPercentEBLL15_18:Dia2Porportion,data = dataSetSmall,nvmax = 11)
regsummary <-summary(regfull)

test <- lm(rentTotalPop~ TotalPercentEBLL15_18 + anxietyPorportion + depressionPorportion + hyper2Porportion + Dia2Porportion + TotalPopulation 
           + TotalPercentEBLL15_18:anxietyPorportion + TotalPercentEBLL15_18:depressionPorportion,data = dataSetSmall)
dataSetSmall
summary(test)
plot(regfull, scale = "r2")
plot(regfull, scale = "adjr2")
plot(regfull, scale = "Cp")
plot(regfull, scale = "bic")
```

Checking for overfitting 

```{r}
set.seed(343)
shuf <- sample(1:nrow(dataSetSmall))
dataShuf <- dataSetSmall[shuf,] 

trainid <- sample(1:nrow(regSmall), nrow(regSmall)*0.8 , replace=F)
train <- regSmall[trainid,]
test <- regSmall[-trainid,]

modelTrain <- lm(rentTotalPop~ TotalPercentEBLL15_18 + anxietyPorportion + depressionPorportion + hyper2Porportion + Dia2Porportion + TotalPercentEBLL15_18:anxietyPorportion + TotalPercentEBLL15_18:depressionPorportion, data = train)

summary(modelTrain)$r.squared

shrinkage <- (summary(fullModel)$r.squared - summary(modelTrain)$r.squared)
shrinkage
```

Cross Validation

```{r}
set.seed(343)
shuf <- sample(1:nrow(dataSetSmall))
dataShuf <- dataSetSmall[shuf,] 

ind1 <- seq(1,349,38)
ind2 <- seq(38,386,38)
ind2[10] <- 387

cv.MSE <- c(1:10)
r2 <- c(1:10)
shrink <- c(1:10)
for(i in 1:10){
  
  temp.train <- -(ind1[i]:ind2[i])
  temp.test <- (ind1[i]:ind2[i])
  temp.x <- dataShuf[temp.train,]
  
  temp.model <- lm(rentTotalPop ~ TotalPercentEBLL15_18 + anxietyPorportion + depressionPorportion + hyper2Porportion + Dia2Porportion +    TotalPercentEBLL15_18:anxietyPorportion + TotalPercentEBLL15_18:depressionPorportion, data = temp.x)
  
  yhat <- predict(temp.model, dataShuf[temp.test,])
  cv.MSE[i] <- mean( (yhat - dataShuf[temp.test,]$rentTotalPop)^2 ) 
  r2[i] <- summary(temp.model)$r.squared
  shrink[i] <- (summary(fullModel)$r.squared - r2[i])
}
r2
shrink
mean(shrink)
```

